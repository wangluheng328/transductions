experiment:
  dataset:
    name: ms-passivization-de
    input: ms-passivization.tsv
    source_format: sequence
    target_format: sequence
    overwrite: false
    transform_field: target
    splits:
      train: 80
      test: 10
      val: 10
  hyperparameters:
    epochs: 50
    batch_size: 5
    lr: 0.001
    tolerance: 0.0001
    num_iters_eval: 1000
    min_iters: 30000
    patience: 5
    tf_ratio: 0.0
    cuda: 0
  model:
    name: LSTM-Multiplicative
    encoder:
      unit: LSTM
      type: sequence
      dropout: 0
      num_layers: 1
      hidden_size: 256
      max_length: 0
      embedding_size: 256
      bidirectional: false
    decoder:
      unit: LSTM
      type: sequence
      dropout: 0
      num_layers: 1
      max_length: 30
      hidden_size: 256
      attention: Multiplicative
      embedding_size: 256
  name: ms-passivization-de
pretty_print: true

[2021-10-06 16:39:05,530][core.trainer][INFO] - DEVICE: cuda
[2021-10-06 16:39:05,530][core.dataset.base_dataset][INFO] - Initializing dataset
[2021-10-06 16:39:05,531][core.dataset.base_dataset][INFO] - Constructing fields from dataset.
[2021-10-06 16:39:08,762][core.trainer][INFO] - TransductionDataset(
 splits: [val (1000 sequences), train (100000 sequences), test (10000 sequences), gen (10000 sequences)]
 fields: [source, annotation, target]
)
[2021-10-06 16:39:08,763][core.models.base_model][INFO] - Initializing model
