experiment:
  dataset:
    name: ms-passivization-de
    input: ms-passivization.tsv
    source_format: sequence
    target_format: sequence
    overwrite: false
    transform_field: target
    splits:
      train: 80
      test: 10
      val: 10
  hyperparameters:
    epochs: 50
    batch_size: 5
    lr: 0.001
    tolerance: 0.0001
    num_iters_eval: 1000
    min_iters: 30000
    patience: 5
    tf_ratio: 0.5
    cuda: 0
  model:
    name: LSTM-Multiplicative
    encoder:
      unit: LSTM
      type: sequence
      dropout: 0
      num_layers: 1
      hidden_size: 256
      max_length: 0
      embedding_size: 256
      bidirectional: false
    decoder:
      unit: LSTM
      type: sequence
      dropout: 0
      num_layers: 1
      max_length: 30
      hidden_size: 256
      attention: Multiplicative
      embedding_size: 256
  name: passiv-de-lstm-1layer
pretty_print: true

[2021-10-26 20:05:06,222][core.trainer][INFO] - DEVICE: cuda
[2021-10-26 20:05:06,226][core.dataset.base_dataset][INFO] - Initializing dataset
[2021-10-26 20:05:06,250][core.dataset.base_dataset][INFO] - Constructing fields from dataset.
[2021-10-26 20:05:09,396][core.trainer][INFO] - TransductionDataset(
 splits: [val (1000 sequences), train (100000 sequences), test (10000 sequences), gen (10000 sequences)]
 fields: [source, annotation, target]
)
[2021-10-26 20:05:09,457][core.models.base_model][INFO] - Initializing model
[2021-10-26 20:05:13,807][core.trainer][INFO] - TransductionModel(
  (_encoder): TransductionSequenceEncoder(
    (module): Sequential(
      (0): Embedding(83, 256)
      (1): LSTM(256, 256)
    )
  )
  (_decoder): LSTMSequenceDecoder(
    (_embedding): Embedding(97, 256)
    (_unit): LSTM(512, 256)
    (_out): Linear(in_features=256, out_features=97, bias=True)
    (_attention): MultiplicativeAttention(
      (key_map): Linear(in_features=256, out_features=256, bias=True)
      (val_map): Linear(in_features=256, out_features=256, bias=True)
    )
  )
)
[2021-10-26 20:05:13,807][core.trainer][INFO] - Beginning training
[2021-10-26 20:05:14,025][core.metrics.meter][INFO] - Logging with tensorboard; view with `tensorboard --logdir=/scratch/lw2534/lab/transductions/outputs/passiv-de-lstm-1layer/LSTM-Multiplicative/2021-10-26_20-05-06/tensorboard`
[2021-10-26 20:05:14,025][core.trainer][INFO] - EPOCH 1 / 50
[2021-10-26 20:05:14,026][core.trainer][INFO] - Computing metrics for 'train' dataset
