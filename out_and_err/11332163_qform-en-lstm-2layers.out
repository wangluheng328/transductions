experiment:
  dataset:
    name: ms-question-en
    input: ms-question.tsv
    source_format: sequence
    target_format: sequence
    overwrite: false
    transform_field: target
    splits:
      train: 80
      test: 10
      val: 10
  hyperparameters:
    epochs: 100
    batch_size: 5
    lr: 0.001
    tolerance: 0.0001
    num_iters_eval: 1000
    min_iters: 30000
    patience: 5
    tf_ratio: 0.5
    cuda: 0
  model:
    name: LSTM-Multiplicative
    encoder:
      unit: LSTM
      type: sequence
      dropout: 0
      num_layers: 2
      hidden_size: 256
      max_length: 0
      embedding_size: 256
      bidirectional: false
    decoder:
      unit: LSTM
      type: sequence
      dropout: 0
      num_layers: 2
      max_length: 30
      hidden_size: 256
      attention: Multiplicative
      embedding_size: 256
  name: qform-en-lstm-2layers
pretty_print: true

[2021-10-30 17:54:08,681][core.trainer][INFO] - DEVICE: cuda
[2021-10-30 17:54:08,681][core.dataset.base_dataset][INFO] - Initializing dataset
[2021-10-30 17:54:08,681][core.dataset.base_dataset][INFO] - Constructing fields from dataset.
[2021-10-30 17:54:11,740][core.trainer][INFO] - TransductionDataset(
 splits: [val (1000 sequences), train (100000 sequences), test (10000 sequences), gen (10000 sequences)]
 fields: [source, annotation, target]
)
[2021-10-30 17:54:11,741][core.models.base_model][INFO] - Initializing model
[2021-10-30 17:54:14,848][core.trainer][INFO] - TransductionModel(
  (_encoder): TransductionSequenceEncoder(
    (module): Sequential(
      (0): Embedding(68, 256)
      (1): LSTM(256, 256, num_layers=2)
    )
  )
  (_decoder): LSTMSequenceDecoder(
    (_embedding): Embedding(71, 256)
    (_unit): LSTM(512, 256, num_layers=2)
    (_out): Linear(in_features=256, out_features=71, bias=True)
    (_attention): MultiplicativeAttention(
      (key_map): Linear(in_features=256, out_features=256, bias=True)
      (val_map): Linear(in_features=256, out_features=256, bias=True)
    )
  )
)
[2021-10-30 17:54:14,848][core.trainer][INFO] - Beginning training
[2021-10-30 17:54:14,852][core.metrics.meter][INFO] - Logging with tensorboard; view with `tensorboard --logdir=/scratch/lw2534/lab/transductions/outputs/qform-en-lstm-2layers/LSTM-Multiplicative/2021-10-30_17-54-08/tensorboard`
[2021-10-30 17:54:14,852][core.trainer][INFO] - EPOCH 1 / 100
[2021-10-30 17:54:14,852][core.trainer][INFO] - Computing metrics for 'train' dataset
[2021-10-30 17:54:37,387][core.trainer][INFO] - Computing metrics for 'val' dataset
[2021-10-30 17:54:39,470][core.metrics.meter][INFO] - Meter:
SequenceAccuracy:	0.000
TokenAccuracy:	0.024
LengthAccuracy:	0.873
1st Token Accuracy:	0.034
2nd Token Accuracy:	0.038
Average Loss:	4.247
[2021-10-30 17:54:56,908][core.trainer][INFO] - Computing metrics for 'val' dataset
[2021-10-30 17:54:58,598][core.metrics.meter][INFO] - Meter:
SequenceAccuracy:	0.000
TokenAccuracy:	0.072
LengthAccuracy:	0.392
1st Token Accuracy:	0.003
2nd Token Accuracy:	0.007
Average Loss:	4.235
[2021-10-30 17:55:18,237][core.trainer][INFO] - Computing metrics for 'val' dataset
[2021-10-30 17:55:19,820][core.metrics.meter][INFO] - Meter:
SequenceAccuracy:	0.000
TokenAccuracy:	0.103
LengthAccuracy:	0.400
1st Token Accuracy:	0.000
2nd Token Accuracy:	0.000
Average Loss:	4.210
[2021-10-30 17:55:39,754][core.trainer][INFO] - Computing metrics for 'val' dataset
[2021-10-30 17:55:41,302][core.metrics.meter][INFO] - Meter:
SequenceAccuracy:	0.000
TokenAccuracy:	0.100
LengthAccuracy:	0.426
1st Token Accuracy:	0.000
2nd Token Accuracy:	0.000
Average Loss:	4.189
[2021-10-30 17:56:01,099][core.trainer][INFO] - Computing metrics for 'val' dataset
[2021-10-30 17:56:02,619][core.metrics.meter][INFO] - Meter:
SequenceAccuracy:	0.000
TokenAccuracy:	0.096
LengthAccuracy:	0.414
1st Token Accuracy:	0.000
2nd Token Accuracy:	0.000
Average Loss:	4.168
[2021-10-30 17:56:22,077][core.trainer][INFO] - Computing metrics for 'val' dataset
[2021-10-30 17:56:23,488][core.metrics.meter][INFO] - Meter:
SequenceAccuracy:	0.000
TokenAccuracy:	0.093
LengthAccuracy:	0.398
1st Token Accuracy:	0.000
2nd Token Accuracy:	0.000
Average Loss:	4.145
[2021-10-30 17:56:42,507][core.trainer][INFO] - Computing metrics for 'val' dataset
[2021-10-30 17:56:43,922][core.metrics.meter][INFO] - Meter:
SequenceAccuracy:	0.000
TokenAccuracy:	0.096
LengthAccuracy:	0.392
1st Token Accuracy:	0.000
2nd Token Accuracy:	0.000
Average Loss:	4.120
[2021-10-30 17:57:02,548][core.trainer][INFO] - Computing metrics for 'val' dataset
[2021-10-30 17:57:03,813][core.metrics.meter][INFO] - Meter:
SequenceAccuracy:	0.000
TokenAccuracy:	0.101
LengthAccuracy:	0.382
1st Token Accuracy:	0.000
2nd Token Accuracy:	0.000
Average Loss:	4.097
[2021-10-30 17:57:21,779][core.trainer][INFO] - Computing metrics for 'val' dataset
[2021-10-30 17:57:23,023][core.metrics.meter][INFO] - Meter:
SequenceAccuracy:	0.000
TokenAccuracy:	0.103
LengthAccuracy:	0.322
1st Token Accuracy:	0.000
2nd Token Accuracy:	0.000
Average Loss:	4.079
[2021-10-30 17:57:40,522][core.trainer][INFO] - Computing metrics for 'val' dataset
[2021-10-30 17:57:41,770][core.metrics.meter][INFO] - Meter:
SequenceAccuracy:	0.000
TokenAccuracy:	0.102
LengthAccuracy:	0.282
1st Token Accuracy:	0.000
2nd Token Accuracy:	0.000
Average Loss:	4.057
[2021-10-30 17:57:58,992][core.trainer][INFO] - Computing metrics for 'val' dataset
[2021-10-30 17:58:00,237][core.metrics.meter][INFO] - Meter:
SequenceAccuracy:	0.000
TokenAccuracy:	0.103
LengthAccuracy:	0.268
1st Token Accuracy:	0.000
2nd Token Accuracy:	0.000
Average Loss:	4.031
[2021-10-30 17:58:17,214][core.trainer][INFO] - Computing metrics for 'val' dataset
[2021-10-30 17:58:18,459][core.metrics.meter][INFO] - Meter:
SequenceAccuracy:	0.000
TokenAccuracy:	0.100
LengthAccuracy:	0.225
1st Token Accuracy:	0.000
2nd Token Accuracy:	0.000
Average Loss:	4.011
[2021-10-30 17:58:35,068][core.trainer][INFO] - Computing metrics for 'val' dataset
[2021-10-30 17:58:36,314][core.metrics.meter][INFO] - Meter:
SequenceAccuracy:	0.000
TokenAccuracy:	0.100
LengthAccuracy:	0.195
1st Token Accuracy:	0.000
2nd Token Accuracy:	0.000
Average Loss:	3.990
